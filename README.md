ğŸ§ Taller 1 - MLOps
API de ClasificaciÃ³n de Penguins con FastAPI y Docker

Este proyecto fue desarrollado como parte del Taller 1 de MLOps.
Se entrena un modelo de Machine Learning utilizando el dataset palmerpenguins y se expone mediante una API construida con FastAPI, la cual es desplegada dentro de un contenedor Docker.

ğŸ“‚ Estructura del Proyecto
TALLER_1/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ penguins_species_model.pkl
â”‚   â””â”€â”€ requirements
â”‚
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md

ğŸ“Œ DescripciÃ³n de los componentes

main.py â†’ Contiene la implementaciÃ³n de la API con FastAPI.

penguins_species_model.pkl â†’ Modelo entrenado para clasificaciÃ³n de especies.

requirements â†’ Archivo de dependencias del proyecto.

Dockerfile â†’ Archivo de configuraciÃ³n para crear la imagen Docker.

README.md â†’ DocumentaciÃ³n del proyecto.

âš™ï¸ Entrenamiento del Modelo

El modelo fue entrenado previamente utilizando el dataset palmerpenguins.

El archivo serializado generado es:

penguins_species_model.pkl


Este archivo es cargado por la API para realizar predicciones.

ğŸš€ EjecuciÃ³n Local (sin Docker)

Desde la carpeta app, instalar dependencias:

pip install -r requirements


Luego ejecutar:

uvicorn main:app --reload --port 8989


Abrir en el navegador:

http://localhost:8989/docs

ğŸ³ EjecuciÃ³n con Docker

Desde la raÃ­z del proyecto (donde estÃ¡ el Dockerfile):

Construir la imagen:
docker build -t penguin-api .

Ejecutar el contenedor:
docker run -p 8989:8989 penguin-api


La API quedarÃ¡ disponible en:

http://localhost:8989/docs

ğŸ“¡ Endpoint Principal
POST /predict

Recibe las siguientes variables:

bill_length_mm

bill_depth_mm

flipper_length_mm

body_mass_g

Ejemplo de entrada JSON:

{
  "bill_length_mm": 50,
  "bill_depth_mm": 15,
  "flipper_length_mm": 200,
  "body_mass_g": 4000
}


Retorna:

Especie predicha del pingÃ¼ino

ğŸ§  TecnologÃ­as Utilizadas

Python 3.10

FastAPI

Uvicorn

Scikit-learn

Docker

ğŸ¯ Objetivo del Proyecto

Aplicar conceptos fundamentales de MLOps:

SerializaciÃ³n de modelos

CreaciÃ³n de API para inferencia

ContenerizaciÃ³n con Docker

ExposiciÃ³n del servicio en puerto 8989

ğŸ‘¨â€ğŸ’» Autor

Daniel Velasco
MaestrÃ­a en Inteligencia Artificial